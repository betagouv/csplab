from typing import Dict, List
from uuid import UUID

from django.db import DatabaseError, transaction
from django.db.models import F, Q

from domain.entities.offer import Offer
from domain.exceptions.offer_errors import OfferDoesNotExist
from domain.repositories.document_repository_interface import (
    IUpsertResult,
)
from domain.repositories.offers_repository_interface import IOffersRepository
from domain.services.logger_interface import ILogger
from infrastructure.django_apps.shared.models.offer import OfferModel


class PostgresOffersRepository(IOffersRepository):
    def __init__(self, logger: ILogger):
        self.logger = logger

    def upsert_batch(self, offers_list: List[Offer]) -> IUpsertResult:
        try:
            with transaction.atomic():
                # Get existing models with select_for_update to prevent race conditions
                existing_models = list(
                    OfferModel.objects.filter(
                        external_id__in=[offer.external_id for offer in offers_list]
                    ).select_for_update(of=("self",))
                )

                existing_models_map = {
                    model.external_id: model for model in existing_models
                }
                existing_external_ids = set(existing_models_map.keys())

                # Partition offers into new and existing
                partitioned: Dict[str, List[Offer]] = {"new": [], "existing": []}
                for offer in offers_list:
                    if offer.external_id in existing_external_ids:
                        partitioned["existing"].append(offer)
                    else:
                        partitioned["new"].append(offer)

                created = 0
                updated = 0

                # Bulk create new offers (UUID is generated by entity)
                if partitioned["new"]:
                    new_models = []
                    for offer in partitioned["new"]:
                        # Create model with UUID from entity
                        model = OfferModel.from_entity(offer)
                        new_models.append(model)

                    # Use bulk_create with update_fields to get the generated IDs back
                    created_models = OfferModel.objects.bulk_create(
                        new_models, ignore_conflicts=True
                    )
                    created = len(created_models)

                # Bulk update existing offers
                if partitioned["existing"]:
                    models_to_update = []
                    for offer in partitioned["existing"]:
                        if offer.external_id in existing_models_map:
                            existing_model = existing_models_map[offer.external_id]
                            updated_model = OfferModel.from_entity(offer)
                            # Keep the existing PostgreSQL ID and timestamps
                            updated_model.id = existing_model.id
                            updated_model.created_at = existing_model.created_at
                            models_to_update.append(updated_model)

                    if models_to_update:
                        updated = OfferModel.objects.bulk_update(
                            models_to_update,
                            fields=[
                                "verse",
                                "title",
                                "profile",
                                "mission",
                                "category",
                                "contract_type",
                                "organization",
                                "offer_url",
                                "country",
                                "region",
                                "department",
                                "publication_date",
                                "beginning_date",
                            ],
                        )

            return {"created": created, "updated": updated, "errors": []}

        except Exception as e:
            self.logger.error(f"Database error during bulk upsert: {str(e)}")
            db_error = DatabaseError(
                f"Erreur lors de l'upsert batch des offres: {str(e)}"
            )
            return {
                "created": 0,
                "updated": 0,
                "errors": [
                    {
                        "entity_id": None,
                        "error": f"Database error during bulk upsert: {str(e)}",
                        "exception": db_error,
                    }
                ],
            }

    def find_by_id(self, offer_id: UUID) -> Offer:
        try:
            offer_model = OfferModel.objects.get(id=offer_id)
            return offer_model.to_entity()
        except OfferModel.DoesNotExist as e:
            raise OfferDoesNotExist(offer_id) from e

    def find_by_external_id(self, external_id: str) -> Offer:
        try:
            offer_model = OfferModel.objects.get(external_id=external_id)
            return offer_model.to_entity()
        except OfferModel.DoesNotExist as e:
            raise OfferDoesNotExist(external_id) from e

    def get_all(self) -> List[Offer]:
        offer_models = OfferModel.objects.all()
        return [model.to_entity() for model in offer_models]

    @transaction.atomic
    def get_pending_processing(self, limit: int = 1000) -> List[Offer]:
        qs = (
            OfferModel.objects.filter(archived_at__isnull=True, processing=False)
            .filter(Q(processed_at__isnull=True) | Q(updated_at__gt=F("processed_at")))
            .select_for_update(of=("self",), skip_locked=True)[:limit]
        )

        for obj in qs:
            obj.processing = True
        try:
            OfferModel.objects.bulk_update(qs, ["processing"])
        except Exception as e:
            raise DatabaseError(f"Database error during update: {str(e)}") from e

        return [model.to_entity() for model in qs]
